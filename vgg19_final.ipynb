{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajayogi/Indian-Food-Classification/blob/master/vgg19_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq2oMa29b9WU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61df153a-39a0-48fc-aefc-f29e4782e8ff"
      },
      "source": [
        "pip install split-folders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.6/dist-packages (0.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4xK4NUb_Dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "cbdf5b9f-df52-43d0-f37d-5a09106df47e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeLBss5b_ZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cfa950d-e3f7-4e7d-d70b-15d11f219290"
      },
      "source": [
        "!ls \"gdrive/My Drive/indian food dataset.zip\"\n",
        "!unzip -q \"gdrive/My Drive/indian food dataset.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'gdrive/My Drive/indian food dataset.zip'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thE-ruOZb_nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import split_folders\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "split_folders.ratio('indian food dataset', output=\"final\", seed=1337, ratio=(.8, .2)) # default values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t8lIUrNfx3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c2yYKb_fyGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6c369f5a-0828-4d20-eb86-abe206f68cbe"
      },
      "source": [
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('final/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('final/val',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7999 images belonging to 20 classes.\n",
            "Found 2000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFVdjGb3gR5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG19"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf443sC4gVcD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3678690b-1a6f-4ac5-8be2-a88dc4d87ba4"
      },
      "source": [
        "conv_base = VGG19(weights='imagenet',\n",
        "include_top=False,\n",
        "input_shape=(150, 150, 3))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7qvM2OBgaIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "import os\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(20, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEQ7EjfKgjJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiPqa28ygsmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = ''\n",
        "train_dir = os.path.join(base_dir, 'final/train')\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'final/val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xTTi0__g5AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MB8fJg8g_gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77c692ac-9ee6-490b-8fe1-4fd1734f6736"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, \n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7999 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBxY0fA4hje0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05422ba3-8911-465e-e903-cea5928a3427"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150, 150),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ArdtArhWGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btz1zCx3hZoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1128
        },
        "outputId": "7259dcdd-d5af-4368-c3d8-80f7ed5da063"
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=250,\n",
        "                              epochs=30,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=60)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "250/250 [==============================] - 65s 259ms/step - loss: 2.7842 - acc: 0.1595 - val_loss: 2.4857 - val_acc: 0.2750\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 2.3967 - acc: 0.2977 - val_loss: 2.2017 - val_acc: 0.3640\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 2.1757 - acc: 0.3598 - val_loss: 2.0133 - val_acc: 0.4070\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 2.0489 - acc: 0.3995 - val_loss: 1.9244 - val_acc: 0.4254\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 1.9534 - acc: 0.4245 - val_loss: 1.8438 - val_acc: 0.4533\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 1.8767 - acc: 0.4432 - val_loss: 1.7673 - val_acc: 0.4706\n",
            "Epoch 7/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.8251 - acc: 0.4556 - val_loss: 1.7674 - val_acc: 0.4727\n",
            "Epoch 8/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.7770 - acc: 0.4724 - val_loss: 1.6887 - val_acc: 0.4858\n",
            "Epoch 9/30\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 1.7254 - acc: 0.4822 - val_loss: 1.6640 - val_acc: 0.5137\n",
            "Epoch 10/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.6981 - acc: 0.4952 - val_loss: 1.6277 - val_acc: 0.5026\n",
            "Epoch 11/30\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 1.6723 - acc: 0.5025 - val_loss: 1.6014 - val_acc: 0.5121\n",
            "Epoch 12/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.6459 - acc: 0.5084 - val_loss: 1.6016 - val_acc: 0.5305\n",
            "Epoch 13/30\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 1.6190 - acc: 0.5108 - val_loss: 1.5642 - val_acc: 0.5326\n",
            "Epoch 14/30\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 1.5912 - acc: 0.5245 - val_loss: 1.5478 - val_acc: 0.5452\n",
            "Epoch 15/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.5754 - acc: 0.5246 - val_loss: 1.5085 - val_acc: 0.5488\n",
            "Epoch 16/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.5593 - acc: 0.5346 - val_loss: 1.5392 - val_acc: 0.5383\n",
            "Epoch 17/30\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 1.5329 - acc: 0.5439 - val_loss: 1.5194 - val_acc: 0.5446\n",
            "Epoch 18/30\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 1.5166 - acc: 0.5481 - val_loss: 1.4905 - val_acc: 0.5588\n",
            "Epoch 19/30\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 1.5103 - acc: 0.5486 - val_loss: 1.5068 - val_acc: 0.5551\n",
            "Epoch 20/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.4786 - acc: 0.5574 - val_loss: 1.4902 - val_acc: 0.5567\n",
            "Epoch 21/30\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 1.4765 - acc: 0.5606 - val_loss: 1.4657 - val_acc: 0.5588\n",
            "Epoch 22/30\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 1.4574 - acc: 0.5651 - val_loss: 1.4724 - val_acc: 0.5599\n",
            "Epoch 23/30\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 1.4529 - acc: 0.5661 - val_loss: 1.4564 - val_acc: 0.5657\n",
            "Epoch 24/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.4413 - acc: 0.5683 - val_loss: 1.4701 - val_acc: 0.5593\n",
            "Epoch 25/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.4310 - acc: 0.5760 - val_loss: 1.4379 - val_acc: 0.5714\n",
            "Epoch 26/30\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 1.4132 - acc: 0.5815 - val_loss: 1.4375 - val_acc: 0.5751\n",
            "Epoch 27/30\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 1.4131 - acc: 0.5796 - val_loss: 1.4244 - val_acc: 0.5825\n",
            "Epoch 28/30\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 1.4084 - acc: 0.5842 - val_loss: 1.4345 - val_acc: 0.5699\n",
            "Epoch 29/30\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 1.3884 - acc: 0.5873 - val_loss: 1.4255 - val_acc: 0.5657\n",
            "Epoch 30/30\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 1.3859 - acc: 0.5866 - val_loss: 1.4247 - val_acc: 0.5746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eMiSvUwb9Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BteDuGXyzbLt",
        "colab_type": "code",
        "outputId": "6e633e69-ba11-449e-b068-363aedb99790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "list = os.listdir('final/train/salad') # dir is your directory path\n",
        "number_files = len(list)\n",
        "print(number_files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}